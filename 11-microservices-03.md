# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Решение 1

Для обеспечние процесса разаработки, с учетом необходимых требований, хорошо подходит Gitlab.

* Gitlab имеет ряд функций закрывающих потребности при CI/CD и хранинение того же кода в своих репозиториях, также есть Gitlab container registry.

  (Docker подходит для воспроизведения изолированных сборок и тестов, для минимизации конфликтов.)
 
* Его можно развернуть как в облаке на арендуемом сервере, так и у себя в локальной сети, либо применить в закрытом контуре сети предприятия, для обеспечения большей безопасности.
* Чувствительные данные можно не писать в открытом виде, а использовать переменные, либо интеграция с Hashicorp Vault поможет в безопасном хранении данных.  
* запуск сборки производится по webhooks, pipeline triggers при push/merge. Также по "кнопке" Manual jobs с параметризацией в пайплайнах.
* Gitlab runner заниматся выполением инструкций, описаном в gitlab-ci.yml. Можно выполнять тесты и сборки локально, также в облаках. А также можно регулировать количество одновременных сборок, то есть чем больше Runner'ов подключено к проекту, тем больше одновременных сборок или тестов можно запустить.
  
Kubernetes может использоваться для управления инфраструктурой агентов сборки (GitLab Runners), а также для деплоя приложений.
Развернуть GitLab Runners в Kubernetes, чтобы гибко масштабировать CI/CD. Использовать Helm-чарты для управления конфигурациями развертываний. Автоматизировать развёртывание сервисов в Kubernetes после успешных сборок.

В качестве алтернативы может использоваться jenkins. Совместно с GitHub и Docker.
  



## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Решение 2:
 Для Логов а далее и мониторинга хорошо подходит ELK стек совместно с Fluentd.

* Elasticsearch — высокопроизводительный движок для хранения и поиска данных. Он используется для индексирования и хранения логов, что позволяет эффективно выполнять поиск и фильтрацию по записям.

* Logstash/Fluentd — агент для сбора и доставки логов. Эти инструменты собирают логи из разных источников (stdout приложений, файловые логи, системные логи) и передают их в Elasticsearch.

* Kibana — мощный веб-интерфейс для визуализации данных, собранных в Elasticsearch. Он позволяет разработчикам выполнять поиск по логам, создавать фильтры и дашборды, а также сохранять и делиться результатами поиска.

 * Fluentd может собирать данные из различных источников, обрабатывать их и направлять в различные хранилища данных.

* Logstash будет принимать логи от агентов Fluentd и преобразовывать логи в единому формату.

* Elasticsearch будет хранить логи, для обеспечения отказоустойчивости возможно создать Elasticsearch-кластер.

* Kibana будет удобно отображать логи в web-интерфейсе. Используя Kibana можно создавать различные Dashboard для удобного просмотра логов, подсчета каких-либо событий, использовать различные временные метки.

  в качестве альтернативы можно использовать Grafana Loki.
  *Promtail собирает логи и отправляет их в Loki, который хранит логи, индексирует метки и метаданные. Grafana запрашивает данные из loki, фильтрует и выбирает желаемые результаты логов.

  Преимущества:
  * На 10x меньше ресурсов чем ELK
  * Простая установка и управление
  * Нативная интеграция с Grafana
  * Эффективное хранение логов
## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

Для мониторинга хорошо подойдет связка Grafana + Prometeus 

* Prometheus - это система мониторинга и оповещения с открытым исходным кодом. Позволяет собирать метрики с различных источников, может выполнять агрегацию данных, быстро получать эти данные используя запросы к базе, визуализировать данные и оповещать о проблемах в сервисах на основе полученных метрик. Prometheus получает данные от различных агентов, например, может получить метрики загрузки CPU от node_exporter или метрики Docker контейнеров от Cadvisor. Также может работать совместно с Telegraf, который в свою очередь способен получать метрики из очень большого множества источников.

* Grafana - web-интерфейс для визуализации данных. Может строить графики, Dashboard, визуализирует данные из большого числа систем мониторинга и большого числа разных метрик. К нему можно подключить большое количество источников, таких как Telegraf, Prometheus, InfluxDB и т.д.

